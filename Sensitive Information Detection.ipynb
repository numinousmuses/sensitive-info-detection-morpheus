{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7cf67c-472d-40d4-9b3d-caf6513248eb",
   "metadata": {},
   "source": [
    "![DLI Logo](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d79f8-8a3b-4632-b816-e385246f5cf5",
   "metadata": {},
   "source": [
    "# Sensitive Information Detection with Morpheus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac617bc-5bdb-4364-a159-f9dbfae27d6e",
   "metadata": {},
   "source": [
    "In this notebook, you will get to perform sensitive information detection using Morpheus, similar to what was discussed in the GTC session _[Morpheus: AI Inferencing for Cybersecurity Pipelines](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s33291/)_ you viewed earlier in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39672bf4-15ac-4dc3-bef7-a2dafc2b8640",
   "metadata": {},
   "source": [
    "## Notebook Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d25d7-8547-486b-989c-d442c915781d",
   "metadata": {},
   "source": [
    "- **Coding Environment**: Get an overview of the relevant features of this GPU-accelerated coding environment.\n",
    "- **Data Overview**: Examine the data we will be sending through the Morpheus pipeline and performing sensitive information detection on.\n",
    "- **SID Pipeline Overview**: Understand the Morpheus SID pipeline command.\n",
    "- **Run the SID Pipeline**: Use Morpheus to launch a SID pipeline.\n",
    "- **Results Overview**: Examine the output of the Morpheus SID pipeline.\n",
    "- **Next Steps**: Learn how to get started with Morpheus for your own project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68398b00-ac2a-47c5-b20a-caa411073fe3",
   "metadata": {},
   "source": [
    "## Coding Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1bc98c-3581-4669-b4cd-3e71a0a6adea",
   "metadata": {},
   "source": [
    "This interactive JupyterLab environment has a number of features that are relevant to the Morpheus pipeline that you will be running. In this section we give an overview of those you will be using in this content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ed4ce-e126-48ec-8f5f-844fca62f8c2",
   "metadata": {},
   "source": [
    "### NVIDIA GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac813dc0-4c27-41b3-84da-e91ab4462b97",
   "metadata": {},
   "source": [
    "This environment is backed by an NVIDIA GPU. Run the following cell to see details for the GPU provided in this environment. Note: using `!` at the beginning of a Jupyter Python cell (like the one below) allows you to execute command line commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad7265-aef8-4ba8-94de-5592ff5a093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7b8d7-fcb1-4fc7-8d48-c8cf6338f57d",
   "metadata": {},
   "source": [
    "### Morpheus SDK CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dba2c4-72fd-43f9-bdcc-444b5362cc36",
   "metadata": {},
   "source": [
    "You will be using the Morpheus SDK CLI to execute pipelines. The SDK CLI is already installed in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb61285-120b-46fe-aec0-2c8db7449e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!morpheus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817f7ac-3489-49d5-8c63-aac233db4f7e",
   "metadata": {},
   "source": [
    "### Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e81643-f321-42bc-9d08-b0888f389bf0",
   "metadata": {},
   "source": [
    "In addition to running command line commands from Jupyter cells using `!`, JupyterLab also provides terminals where you can run command line commands directly. You can also use the JupyterLab launcher to start a new terminal tab anytime you like: from the Jupyter menu above choose *File -> New Launcher* and then click the *Terminal* icon from the available options.\n",
    "\n",
    "Open the terminal now and execute the `morpheus` command. Following the guidance of the output, feel free to try out some of the `help` command to see a little more about the capabilities of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb7b2-1c6c-46c0-ade5-f1fd79086456",
   "metadata": {},
   "source": [
    "### Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece0379-a1cd-4d5d-859e-c0661da92251",
   "metadata": {},
   "source": [
    "We will using the [Triton inference server](https://developer.nvidia.com/nvidia-triton-inference-server) to perform inference as a part of our Morpheus pipeline. A Triton server is already up and running in this environment and is available at the hostname `triton`. Run the cell below to send a GET request to Triton's readiness check endpoint. A response that includes `200 OK` indicates that the Triton server is up and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368229c-0db4-4d43-affb-d85d054e51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v triton:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cde28-7630-4bcd-86ad-50bd41b3c03a",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce15bc-3035-4e8c-ae07-ef395f5d3737",
   "metadata": {},
   "source": [
    "In this example we will be streaming data into the pipeline from file, namely `data/pcap_dump.jsonlines`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fbb34-10cb-4e2c-92b4-7e7706d8997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh data/pcap_dump.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e5d7b-d440-4d80-a9ef-5e96ed32afae",
   "metadata": {},
   "source": [
    "`pcap_dump.jsonlines` contains 93085 packet captures, each represented as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc60d5-fb69-4412-8caa-e433fcbb65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/pcap_dump.jsonlines | wc -l # Count number of lines / packet captures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b869d-b125-4ec8-800a-70648e7df8fc",
   "metadata": {},
   "source": [
    "We will be using the [`jq`](https://stedolan.github.io/jq/) library to help us read both this input JSON data, and later the output data. Run the following cell to look at 3 arbitrary packet captures from the input data, paying special attention to the `data` fields, which might include sensitive information we would like know is being sent through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9b490-2923-494c-854b-7949a8f5fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at 3 arbitrary packet captures at indices `1`, `31`, `2022`. Feel free to modify the values inside the `[]` to view different packet captures.\n",
    "!cat data/pcap_dump.jsonlines | jq -s '.[1,31,2022]' | tr -d '\\\\' # Remove backslashes for easier reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8874f43-5955-45d3-bcc2-dd8c07a540e8",
   "metadata": {},
   "source": [
    "## SID Pipeline Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37228568-0fbb-4853-b417-3830d90d4c8e",
   "metadata": {},
   "source": [
    "We use the `morpheus` command line tool to construct pipelines, which can consume data from a variety of sources, perform various preprocessing operations on the data, do inference on the preprocessed data, postprocess the data, and send the results of the pipeline to a variety of destinations.\n",
    "\n",
    "We will be using the following pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecec33-2947-4790-8dc7-6972620dfb70",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus --log_level=DEBUG run \\\n",
    "    --num_threads=5 \\\n",
    "    --edge_buffer_size=32 \\\n",
    "    --use_cpp=True \\\n",
    "    --pipeline_batch_size=1024 \\\n",
    "    --model_max_batch_size=32 \\\n",
    "    pipeline-nlp \\\n",
    "        --labels_file=/dli/task/data/labels_nlp.txt \\\n",
    "        --model_seq_length=256 \\\n",
    "        from-file --filename=/dli/task/data/pcap_dump.jsonlines \\\n",
    "        deserialize \\\n",
    "        preprocess --vocab_hash_file=/dli/task/data/bert-base-uncased-hash.txt --truncation=True --do_lower_case=True --add_special_tokens=False \\\n",
    "        monitor --description='Preprocessing rate' \\\n",
    "        inf-triton --force_convert_inputs=True --model_name=sid-minibert-onnx --server_url=triton:8001 \\\n",
    "        monitor --description='Inference rate' --smoothing=0.001 --unit inf \\\n",
    "        add-class \\\n",
    "        filter \\\n",
    "        serialize --exclude '^ts_' \\\n",
    "        to-file --filename=/dli/task/data/output/sid-minibert-onnx-output.jsonlines --overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2b33c-3ca0-45b7-901f-142f9c7fd7f9",
   "metadata": {},
   "source": [
    "Before running the pipeline, let's take a look at many of its key components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b2a59-b92e-41b9-a57c-b9965ce2643f",
   "metadata": {},
   "source": [
    "### Running a Morpheus Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379a82c-b921-44fc-bbbb-3acf6fa29ca3",
   "metadata": {},
   "source": [
    "The first part of the pipeline consists of calling `morpheus run` and passing it a variety of command line arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd38ea7-c6a4-4577-83e8-b93eed1ef779",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus --log_level=DEBUG run \\\n",
    "    --num_threads=5 \\\n",
    "    --edge_buffer_size=32 \\\n",
    "    --use_cpp=True \\\n",
    "    --pipeline_batch_size=1024 \\\n",
    "    --model_max_batch_size=32 \\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e539a2-2cea-47a7-9a2d-7837095d594b",
   "metadata": {},
   "source": [
    "Using `morpheus run --help` we can see the purpose of each of these command line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d52903-7bb5-43d9-ab88-ee5f8eaae76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!morpheus run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b07d2-06df-483d-ae25-25de8ab094ea",
   "metadata": {},
   "source": [
    "### Running an NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529e12c-740e-4c36-8ba0-aff96046dcc1",
   "metadata": {},
   "source": [
    "Our pipeline will perform sensitive information detection by doing inference on each packet capture using a pre-trained NLP model, therefore we will use the `morpheus run pipeline-nlp` subcommand:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6408338-b194-4588-ae79-c6d83f0a4094",
   "metadata": {},
   "source": [
    "```sh\n",
    "pipeline-nlp \\\n",
    "        --labels_file=/dli/task/data/labels_nlp.txt\n",
    "        --model_seq_length=256 \\\n",
    "        from-file --filename=/dli/task/data/pcap_dump.jsonlines \\\n",
    "        deserialize \\\n",
    "        preprocess --vocab_hash_file=/dli/task/data/bert-base-uncased-hash.txt --truncation=True --do_lower_case=True --add_special_tokens=False \\\n",
    "        monitor --description='Preprocessing rate' \\\n",
    "        inf-triton --force_convert_inputs=True --model_name=sid-minibert-onnx --server_url=triton:8001 \\\n",
    "        monitor --description='Inference rate' --smoothing=0.001 --unit inf \\\n",
    "        add-class \\\n",
    "        filter \\\n",
    "        serialize --exclude '^ts_' \\\n",
    "        to-file --filename=/dli/task/data/output/sid-minibert-onnx-output.jsonlines --overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bb513-68d6-4882-b4b3-5b37e5282c59",
   "metadata": {},
   "source": [
    "### Input and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e2285-4ede-47ca-9c00-14c34439e255",
   "metadata": {},
   "source": [
    "We will provide the pipeline a labels file, via the `--labels_file` argument that lists the classes we would like to identify in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7de64e-64bd-4b4d-9678-c112a7c683e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/labels_nlp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7c807-6952-49d0-a000-0968096211f4",
   "metadata": {},
   "source": [
    "As examined earlier, we will use the input file `data/pcap_dump.jsonlines` as input into the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df1750-87ae-4f4f-902f-4bcb1cf5c88a",
   "metadata": {},
   "source": [
    "`deserialize` deserializes the input from JSON, and `preprocess` converts the words from input into tokens for inference by the NLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd53c8b-eb43-4afc-8acb-903fce30ce10",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3a28-8119-4adc-954c-25b1cd4a7be7",
   "metadata": {},
   "source": [
    "With `inf-triton` we use the Triton inference server with a minibert NLP model fine-tuned for SID to perform inference on each of the incoming packet captures. The model has already been loaded into Triton for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bc0dce-bd2f-427d-b7e0-2fb7346ffacc",
   "metadata": {},
   "source": [
    "### Postprocessing and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc77d23-9d7d-44ef-8b40-d2467dc22c6c",
   "metadata": {},
   "source": [
    "After performing inference on each of the captured packets, we use the `add-class` argument to add detected classifications to each model before serializing the classifications and writing them back to file at `data/output/sid-minibert-onnx-output.jsonlines`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e761a9f-bab9-4e26-8da2-fde80cf8eff4",
   "metadata": {},
   "source": [
    "## Run the SID Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a8dfe-0bf0-44e3-852e-d8af7c1c9136",
   "metadata": {},
   "source": [
    "Open a JupyterLab terminal and do `./launch_sid.sh` from the command line. In addition to other output, you should see `====Pipeline Started====`.\n",
    "\n",
    "After a minute or less, you will also start to info about the preprocessing and inference rates for the pipeline:\n",
    "\n",
    "```\n",
    "Preprocessing rate: 93085messages [01:02, 1488.33messages/s]\n",
    "Inference rate: 66560inf [01:02, 1070.50inf/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f22e59-9a2f-4872-a0fe-7214f6b4774e",
   "metadata": {},
   "source": [
    "## Results Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2854ed-9371-491a-a474-f96c5d24e516",
   "metadata": {},
   "source": [
    "Now that the pipeline is running, we can confirm that it is writing its results to `data/output/sid-minibert-onnx-output.jsonlines` as we specified in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cc419-42e0-4d7d-8fb9-bcb81ad5618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369f123-73e9-42c9-b5dc-770d13807f56",
   "metadata": {},
   "source": [
    "If you don't see `sid-minibert-onnx-output.jsonlines` in the output above, wait a few seconds for the pipeline to spin up, and run the cell again until you can confirm it is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90d029-0e2a-4447-b13e-9b718118a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the length of the output file once a second for 5 seconds.\n",
    "!for i in {1..5}; do cat data/output/sid-minibert-onnx-output.jsonlines | wc -l; sleep 1; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebc172-6cda-42e0-8055-aead7e15a7ca",
   "metadata": {},
   "source": [
    "Examining the output we can see that the pipeline has correctly labeled packets containing the classes of sensitive information we passed into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47118ef-abeb-4b85-93b8-1f685d94fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/output/sid-minibert-onnx-output.jsonlines | jq -s '.[0:3]' | tr -d '\\\\' # View the first 3 packet captures annotated with SID labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c195f3e-1f60-4b29-a750-d014dcb2b065",
   "metadata": {},
   "source": [
    "### Sample Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d364a-8189-420f-8213-e467a667d713",
   "metadata": {},
   "source": [
    "Here is a small collection of sample outputs highlighting some examples of our pipeline's results. In addition to the sample outputs below, feel free to explore the data yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3f85d-b475-4047-b6bd-85c29b47829e",
   "metadata": {},
   "source": [
    "**Secret Keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20890f74-4a48-4228-b85f-f8d8ec92fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 3 data fields for packets identified as having secret keys.\n",
    "!cat data/output/sid-minibert-onnx-output.jsonlines | \\\n",
    "  jq -s 'map(select(.secret_keys == true) | {data: .data, secret_key: .secret_keys})[0:3]' | \\\n",
    "  `# Remove backslashes for easier reading.` \\\n",
    "  tr -d '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beadfe52-1b8a-4b2d-a1a8-e4b28b07cc83",
   "metadata": {},
   "source": [
    "**Email and Password**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c9f6f-36ea-4396-b184-5ba4d8669bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 3 data fields for packets identified as having both email addresses and passwords.\n",
    "!cat data/output/sid-minibert-onnx-output.jsonlines | \\\n",
    "  jq -s 'map(select(.email == true and .password == true) | {data: .data, email: .email, password: .password})[0:3]' | \\\n",
    "  `# Remove backslashes for easier reading.` \\\n",
    "  tr -d '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40168a66-406e-4557-9cf7-5db31a09e7c8",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c75a0-d405-4c00-848f-cc7c9776af24",
   "metadata": {},
   "source": [
    "There are several steps you can take to learn more and get more experience with Morpheus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18443780-6454-4c76-a51d-8d0a5d18383d",
   "metadata": {},
   "source": [
    "### Morpheus Early Access Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95655c85-c8f2-4e3d-bed6-d7688b704259",
   "metadata": {},
   "source": [
    "Morpheus is currently in early access, and you can [request access today](https://developer.nvidia.com/morpheus-early-access). As a part of the early access program you'll have access to all the components you need to run Morpheus, including, but not limited to:\n",
    "\n",
    "- Containers and Helm Charts for the Morpheus SDK CLI, Triton-backed Morpheus AI engine, Kafka message broker, MLFlow plugin.\n",
    "- Extensive documentation for system setup and Morpheus use.\n",
    "- Several end-to-end example workflows using Morpheus for SID, Anomalous Behavior Profiling, Phishing Detection, Digital Fingerprinting and more.\n",
    "- Collections of notebooks and scripts for model fine-tuning, performance analysis, and more.\n",
    "\n",
    "Signing up for [early access](https://developer.nvidia.com/morpheus-early-access) is quick, easy, and free.\n",
    "\n",
    "Additionally, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2689e5-95e6-4f33-bfbe-206d944ffd48",
   "metadata": {},
   "source": [
    "### GTC On Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05223490-5b9c-4c18-aa9a-27abf1e7400d",
   "metadata": {},
   "source": [
    "Check out several presentations about Morpheus both from NVIDIA, Booz Allen Hamilton, Redhat, and Splunk for free at [GTC On-Demand](https://www.nvidia.com/en-us/on-demand/search/?facet.mimetype[]=event%20session&layout=list&page=1&q=morpheus&sort=date)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c90ea9-51b7-4cc0-8b8d-22d4aa082031",
   "metadata": {},
   "source": [
    "### GTC 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f791ac-c425-4c07-9ee7-72cbb5fd58c8",
   "metadata": {},
   "source": [
    "[Sign up](https://www.nvidia.com/auth/gtc?scope=openid+email+profile&client_id=FNwji43RhQ7B2YKM7B6rC6N7KA_Gu3-ohkaoljY9NJ8&redirect_uri=https%3A%2F%2Fevents.rainfocus.com%2Foauth%2Fnvidia%2F1629402589906001W3aJ&response_type=code&state=a804cc2db39acc087a63bdbb3226aec5de887edc9917f9846386305c1b118ce190236089340893ba3329b39a125b4691) for [GTC 2022](https://www.nvidia.com/gtc/), where there will be lots to discuss and learn about Morpheus, including a full day deep dive workshop on Morpheus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ab1ad-c2e4-4e46-9bd2-552af46dd609",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151446c-3a21-424f-8808-c39ccd8d6ade",
   "metadata": {},
   "source": [
    "Thank you for taking the time to see Morpheus in action. We hope you will find tremendous use with this powerful tool.\n",
    "\n",
    "Please return to the main course page (where you launched this interactive environment from), and continue to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc88ac-e529-412c-b00a-ce335e9dbc78",
   "metadata": {},
   "source": [
    "![DLI Logo](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
